**What are you looking for in your next role?**

I am seeking a role where I can apply my experience in building end-to-end agentic systems to a production environment at scale. My goal is to leverage my expertise in pretraining infrastructure, as demonstrated by my work at SpaceKnow Inc., and my hands-on experience with frameworks like AutoGPT and my own `CinderellaAI` project, to create robust, tool-using agents that can solve complex, open-ended problems.

**Why are you interested in Perplexity?**

Perplexity's focus on building an AI-powered answer engine directly aligns with my experience. At SpaceKnow, I designed and built a distributed data pipeline for LLM pretraining, including a high-throughput scraping system using Playwright and RedisBloom. I am confident I can apply this experience to enhance the data ingestion and processing for your Answering Agent and Deep Research products, improving the accuracy and trustworthiness of your results.

**What are some example multi-turn agent products that youâ€™ve used and what do you like about them?**

Beyond using consumer products, I have hands-on experience building a multi-turn agent with my open-source project, `CinderellaAI`. This iOS app uses a local Phi-3 model for story generation and `whisper.cpp` for speech-to-text, creating a full speech-to-speech conversational loop on-device. What I find most compelling about this architecture is the challenge of optimizing the STT -> LLM -> TTS pipeline for low latency and high accuracy, which is directly applicable to building a responsive Answering Agent for Perplexity.

**Describe a project you worked on recently that you were the most proud of?**

I am most proud of designing the LLM pretraining data pipeline at SpaceKnow Inc. I architected a scalable scraping infrastructure capable of handling high-volume data acquisition using Playwright and RedisBloom. I also implemented the automated preprocessing pipeline leveraging OCR, NLTK, and language detection to handle terabytes of unstructured data. This project demonstrates my ability to build the foundational systems required for training the powerful models that drive agent products.

**Tell me something contrarian that you believe about AI Research that very few other people in the field believe?**

I believe the industry is overly focused on cloud-based, massive-parameter LLMs. My work on the `CinderellaAI` project, which runs a Phi-3 model entirely on-device for a speech-to-speech agent, has convinced me that the future lies in smaller, highly-optimized models that can run locally. This approach not only enhances privacy and reduces latency but also opens up new possibilities for truly personal and context-aware agents that don't rely on a constant internet connection. The key is not just scale, but architectural innovation and efficiency.
